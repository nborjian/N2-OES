import os
import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json


from jvframework.misc import hdd_share
from scipy.signal import find_peaks
from scipy.optimize import curve_fit


# A) Helper: parse shot number from filename
def parse_shot_number_from_filename(fname):
    """
    Looks for a substring like 'shotXX' in the filename (ignoring extension).
    Returns the integer XX or None if not found.
    """
    base_name, _ = os.path.splitext(fname)
    for part in base_name.split("_"):
        if part.lower().startswith("shot"):
            try:
                return int(part.lower().replace("shot", ""))
            except ValueError:
                return None
    return None


# B) Gaussian + local peak fitting
def gaussian(x, amp, x0, sigma, offset):
    """
    Single Gaussian with baseline offset:
    y = amp * exp(-0.5*((x - x0)/sigma)^2) + offset
    """
    return amp * np.exp(-0.5 * ((x - x0) / sigma)**2) + offset


def fit_gaussian_peak(x_array, y_array, peak_index, window=5):
    """
    Fits a Gaussian locally around peak_index +/- window.
    Returns (center_nm, area) or None if fit fails.


    area = amp * sigma * sqrt(2*pi).
    """
    left = max(0, peak_index - window)
    right = min(len(x_array), peak_index + window + 1)


    sub_x = x_array[left:right]
    sub_y = y_array[left:right]


    if len(sub_x) < 5:
        return None


    amp_guess = sub_y.max() - sub_y.min()
    x0_guess = x_array[peak_index]
    sigma_guess = (sub_x[-1] - sub_x[0]) / 6.0
    offset_guess = sub_y.min()


    p0 = [amp_guess, x0_guess, sigma_guess, offset_guess]


    try:
        popt, pcov = curve_fit(gaussian, sub_x, sub_y, p0=p0)
        amp_fit, x0_fit, sigma_fit, offset_fit = popt
        if sigma_fit <= 0:
            return None
        area_val = amp_fit * sigma_fit * math.sqrt(2.0*math.pi)
        return (x0_fit, area_val)
    except RuntimeError:
        return None




# 1) Read the JSON folder -> build a dictionary of parameters by shot number
json_directory = r"H:\Data\tb1\2025-02-05\N2_20Kinlet"
json_directory = hdd_share(json_directory)


json_data = {}  # Maps shot_num -> dict of BP10, TF10, QN11, BF21


for filename in sorted(os.listdir(json_directory)):
    if filename.lower().endswith('.json'):
        shot_num = parse_shot_number_from_filename(filename)
        if shot_num is None:
            continue


        with open(os.path.join(json_directory, filename), 'r') as file:
            data = json.load(file)


        tag_data = data.get("tag", {})
        bp10 = tag_data.get("bp10_pressure", None)
        tf10 = tag_data.get("tf10_power", None)
        qn11 = tag_data.get("qn11_setpoint", None)
        bf21 = tag_data.get("bf21_mf", None)


        # Store in json_data
        json_data[shot_num] = {
            "BP10 Pressure": bp10,
            "TF10 Power": tf10,
            "qn11 Flow": qn11,
            "BF21 Flow": bf21
        }


# 2) Hardcode the two reference tables in memory & unify them into df_ref
data_original = {
    "obs_wl_vac(nm)": [
        740.612, 740.624, 742.364, 744.229, 746.831, 818.487, 818.802, 820.036, 821.072, 821.634,
        822.314, 824.239, 856.774, 859.400, 862.924, 865.589, 868.028, 868.340, 868.615, 870.325,
        871.170, 871.883, 872.889
    ],
    "intens": [
        160.0, 265.0, 685.0, 785.0, 900.0, 400.0, 400.0, 250.0, 300.0, 570.0,
        400.0, 400.0, 500.0, 570.0, 650.0, 500.0, 700.0, 650.0, 500.0, 500.0,
        570.0, 500.0, 250.0
    ],
    "gA(s^-1)": [
        9.12e6, 1.30e7, 2.26e7, 4.76e7, 7.84e7, 4.93e7, 5.00e7, 9.36e6, 2.09e7, 1.36e8,
        5.24e7, 5.24e7, 1.94e7, 4.18e7, 1.07e8, 2.14e7, 2.02e8, 1.13e8, 4.60e7, 4.32e7,
        5.16e7, 3.92e7, 7.50e6
    ],
    "Ei(eV)": [
        12.000143, 12.009612, 10.325909, 10.330094, 10.335896, 10.330094, 10.325909, 10.325909, 10.330094, 10.335896,
        10.330094, 10.335896, 10.679670, 10.679670, 10.689981, 10.689981, 10.335896, 10.330094, 10.325909, 10.325909,
        10.330094, 10.335896, 10.330094
    ],
    "Ek(eV)": [
        13.673759, 13.683201, 11.995575, 11.995575, 11.995575, 11.844477, 11.839709, 11.837430, 11.839709, 11.844477,
        11.837430, 11.839709, 12.126379, 12.121957, 12.126379, 12.121957, 11.763846, 11.757532, 11.752895, 11.750092,
        11.752895, 11.757532, 11.750092
    ],
}
df_original = pd.DataFrame(data_original)
df_original.rename(columns={"gA(s^-1)": "A(s^-1)"}, inplace=True)


data_new = {
    "obs_wl_vac(nm)": [
        574.36, 579.25, 584.25, 589.39, 594.57, 600.09, 605.67, 623.93, 630.88, 638.03,
        645.39, 652.97, 660.80, 668.87, 677.21, 685.83, 714.65, 725.50, 736.75, 748.44,
        760.58, 773.20, 787.44, 802.44, 851.60, 869.53, 888.34, 917.29, 940.38, 964.77,
        990.57, 295.20, 296.10, 297.60, 311.50, 313.50, 315.80, 337.00, 353.60, 357.60,
        375.40, 380.40, 385.60, 389.40, 394.20, 399.70, 405.80, 414.00, 420.00, 426.80,
        391.44, 423.65, 427.81, 459.97, 507.66, 522.83
    ],
    "intens": [
        170.0, 210.0, 210.0, 218.0, 193.0, 154.0, 111.0, 131.0, 211.0, 318.0,
        408.0, 506.0, 548.0, 504.0, 335.0, 142.0, 161.0, 362.0, 590.0, 872.0,
        833.0, 719.0, 166.0, 134.0, 305.0, 862.0,1260.0, 180.0, 252.0, 271.0,
        214.0,   6.0,   6.0,   6.0,   6.0,   8.0,   9.0,  10.0,   8.0,  10.0,
        10.0,  10.0,   5.0,   7.0,   8.0,   9.0,   8.0,   5.0,   6.0,   5.0,
         6.0,   7.0,   8.0,   6.0,   7.0,   7.0
    ],
    "g": [
        3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
        2, 2, 2, 2, 2, 2
    ],
    "A(s^-1)": [
        64900.0, 61100.0, 53800.0, 43800.0, 32500.0, 21400.0, 11900.0, 41400.0, 58600.0, 73100.0,
        81500.0, 81000.0, 70900.0, 52500.0, 30200.0, 10700.0, 20300.0, 43800.0, 68500.0, 83500.0,
        77300.0, 44400.0, 28800.0, 15800.0, 21700.0, 61700.0, 87200.0, 19100.0, 29400.0, 28500.0,
        12500.0, 1.04e7, 8.68e6, 4.81e6, 6.40e6, 1.14e7, 1.38e7, 1.39e7, 5.49e6, 8.88e6,
        4.62e6, 3.34e6, 2.06e6, 2.66e6, 2.77e6, 2.12e6, 9.60e5, 1.66e6, 1.27e6, 7.20e5,
        9.64e6, 3.87e6, 3.48e6, 1.94e6, 6.80e5, 1.36e5
    ],
    "Franck-Condon": [
        0.2595, 0.2374, 0.1990, 0.1564, 0.1118, 0.0719, 0.0393, 0.1516, 0.2046, 0.2493,
        0.2695, 0.2657, 0.2311, 0.1690, 0.0971, 0.0342, 0.0742, 0.1564, 0.2425, 0.2916,
        0.2757, 0.1617, 0.1057, 0.0584, 0.0956, 0.2744, 0.3976, 0.0952, 0.1559, 0.1516,
        0.0688, 0.3367, 0.2536, 0.1330, 0.2117, 0.3413, 0.3949, 0.4527, 0.2033, 0.3291,
        0.1990, 0.1462, 0.1000, 0.1292, 0.1393, 0.1097, 0.0512, 0.0882, 0.0791, 0.0466,
        0.6481, 0.2889, 0.2619, 0.1699, 0.0735, 0.0157
    ],
}
df_new = pd.DataFrame(data_new)


df_ref = pd.concat([df_original, df_new], ignore_index=True)


# 3) Analyze CSVs -> Summaries by shot (Atomic vs. Molecular)
csv_folder = r"H:\Data\tb1\2025-02-05\N2_20Kinlet"
csv_folder = hdd_share(csv_folder)


peak_rows = []
summary_by_shot = {}  # shot_num -> {Sum(Mol), Sum(Atom), Ratio=(Atom/Mol)}


for filename in sorted(os.listdir(csv_folder)):
    if filename.lower().endswith(".csv") and "hr200204" in filename.lower():
        shot_num = parse_shot_number_from_filename(filename)
        if shot_num is None:
            continue


        csv_path = os.path.join(csv_folder, filename)
        csv_path = hdd_share(csv_path)
        df_spectrum = pd.read_csv(csv_path)


        # Suppose we have a wavelength calibration
        wavelength_path = hdd_share(r"H:\Software\OceanInsight\HR2\jvcalibration\wavelengths.csv")
        df_wavelengths = pd.read_csv(wavelength_path)
        calib_cols = df_wavelengths.columns.tolist()


        df_spectrum.columns = ["timestamp"] + calib_cols
        x_values = df_spectrum.columns[1:].astype(float)
        y_values = df_spectrum.iloc[0, 1:].values


        # Exclude if max(300..400 nm) < 500
        mask_300_400 = (x_values >= 300) & (x_values <= 400)
        if mask_300_400.any():
            if y_values[mask_300_400].max() < 500:
                continue
        else:
            continue


        # find peaks
        peaks, _ = find_peaks(y_values, prominence=200)


        sum_mol = 0.0
        sum_atom = 0.0


        for p_idx in peaks:
            fit_result = fit_gaussian_peak(x_values, y_values, p_idx, window=5)
            if fit_result is not None:
                center_nm, area_val = fit_result


                if 200 <= center_nm <= 550:
                    peak_type = "Molecular N2 Peak Areas"
                elif 700 <= center_nm <= 900:
                    peak_type = "Atomic N Peak Areas"
                else:
                    peak_type = "Other"


                # find closest line in df_ref
                idx_closest = (df_ref["obs_wl_vac(nm)"] - center_nm).abs().idxmin()
                A_val = df_ref.loc[idx_closest, "A(s^-1)"]
                area_div_A = np.nan
                if not pd.isna(A_val) and A_val != 0:
                    area_div_A = area_val / A_val


                if peak_type == "Molecular N2 Peak Areas":
                    sum_mol += 0 if pd.isna(area_div_A) else area_div_A
                elif peak_type == "Atomic N Peak Areas":
                    sum_atom += 0 if pd.isna(area_div_A) else area_div_A


                peak_rows.append({
                    "Filename": filename,
                    "ShotNum": shot_num,
                    "Center (nm)": center_nm,
                    "Peak Area": area_val,
                    "A(s^-1)": A_val,
                    "Area / A": area_div_A,
                    "Peak Type": peak_type
                })


        # ratio = Atom / Mol
        ratio_val = np.nan
        if sum_mol != 0:
            ratio_val = sum_atom / sum_mol


        summary_by_shot[shot_num] = {
            "Sum(Mol)": sum_mol,
            "Sum(Atom)": sum_atom,
            "Ratio(Atom/Mol)": ratio_val
        }


# 4) Merge CSV-based summaries with JSON-based parameters by shot number
summary_rows = []
for shot_num, summ_dict in summary_by_shot.items():
    if shot_num in json_data:
        row = {
            "ShotNum": shot_num,
            "Sum(Mol)": summ_dict["Sum(Mol)"],
            "Sum(Atom)": summ_dict["Sum(Atom)"],
            "Ratio(Atom/Mol)": summ_dict["Ratio(Atom/Mol)"],
            "TF10 Power": json_data[shot_num]["TF10 Power"],
            "BP10 Pressure": json_data[shot_num]["BP10 Pressure"],
            "BF21 Flow": json_data[shot_num]["BF21 Flow"]
        }
        summary_rows.append(row)


df_summary = pd.DataFrame(summary_rows)
df_summary.sort_values(by="ShotNum", inplace=True)


df_peaks = pd.DataFrame(peak_rows)
df_peaks.sort_values(by=["ShotNum", "Center (nm)"], inplace=True)


##############################################################################
# 5) Print tables
##############################################################################
print("\n===================== Detailed Fitted Peaks =====================\n")
print(df_peaks.to_string(index=False))


print("\n============ Summaries: Sum(Atomic) vs. Sum(Molecular) by Shot ============\n")
print(df_summary.to_string(index=False))


##############################################################################
# 6) Plots
#   a) Ratio(Atom/Mol) vs. TF10, BP10, BF21
#   b) Sum(Atom) vs. TF10, BP10, BF21
##############################################################################


plt.figure(figsize=(6,4))
plt.scatter(df_summary["TF10 Power"], df_summary["Ratio(Atom/Mol)"], color="b")
plt.title("Ratio(Atom/Mol) vs. TF10 Power")
plt.xlabel("TF10 Power (W)")
plt.ylabel("Ratio(Atom/Mol)")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,4))
plt.scatter(df_summary["BP10 Pressure"], df_summary["Ratio(Atom/Mol)"], color="r")
plt.title("Ratio(Atom/Mol) vs. BP10 Pressure")
plt.xlabel("BP10 Pressure (kPa)")
plt.ylabel("Ratio(Atom/Mol)")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,4))
plt.scatter(df_summary["BF21 Flow"], df_summary["Ratio(Atom/Mol)"], color="g")
plt.title("Ratio(Atom/Mol) vs. BF21 Flow")
plt.xlabel("BF21 Flow (slpm)")
plt.ylabel("Ratio(Atom/Mol)")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,4))
plt.scatter(df_summary["ShotNum"], df_summary["Ratio(Atom/Mol)"], color="g")
plt.title("Ratio(Atom/Mol) vs. Shot Number")
plt.xlabel("Shot Number")
plt.ylabel("Ratio(Atom/Mol)")
plt.grid(True)
plt.tight_layout()
plt.show()


# Now the three Sum(Atom) plots
plt.figure(figsize=(6,4))
plt.scatter(df_summary["TF10 Power"], df_summary["Sum(Atom)"], color="b")
plt.title("Sum(Atomic) vs. TF10 Power")
plt.xlabel("TF10 Power (W)")
plt.ylabel("Sum(Atomic Peak Areas / A)")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,4))
plt.scatter(df_summary["BP10 Pressure"], df_summary["Sum(Atom)"], color="r")
plt.title("Sum(Atomic) vs. BP10 Pressure")
plt.xlabel("BP10 Pressure (kPa)")
plt.ylabel("Sum(Atomic Peak Areas / A)")
plt.grid(True)
plt.tight_layout()
plt.show()


plt.figure(figsize=(6,4))
plt.scatter(df_summary["BF21 Flow"], df_summary["Sum(Atom)"], color="g")
plt.title("Sum(Atomic) vs. BF21 Flow")
plt.xlabel("BF21 Flow (slpm)")
plt.ylabel("Sum(Atomic Peak Areas / A)")
plt.grid(True)
plt.tight_layout()
plt.show()
